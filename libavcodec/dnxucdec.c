/*
 * Avid DNxUncomressed / SMPTE RDD 50 decoder
 * Copyright (c) 2024 Martin Schitter
 *
 * This file is part of FFmpeg.
 *
 * FFmpeg is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 *
 * FFmpeg is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with FFmpeg; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
 */

/*
 This decoder for DNxUncompressed video data is mostly based on
 reverse engineering of output generated by DaVinci Resolve 19
 but was later also checked against the SMPTE RDD 50 specification.

 Not all DNxUncompressed pixel format variants are supported,
 but at least an elementary base set is already usable:

  - YUV 4:2:2 8/10/12/16bit/half/float   (16bit untested)
    YUV 4:4:4 8/16bit/half/float         (all untested!)
  - RGB 8/10/12/16bit/half/float         (16bit untested)
    Alpha/Y 8/16bit                      (all untested!)

    TODO: Compositions of multiple components aren't supportet until now.
    TODO: This also hinders Image+Alpha use in one file.

*/

#include "avcodec.h"
#include "bytestream.h"
#include "codec_internal.h"
#include "decode.h"
#include "libavutil/imgutils.h"
#include "libavutil/intreadwrite.h"
#include "thread.h"

static int pass_through(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    int linesize[4], ret;

    if ((ret = av_image_fill_linesizes(linesize, frame->format, frame->width)) < 0)
        return ret;

    for (int y = 0; y < frame->height; y++)
        bytestream2_get_buffer(gb, frame->data[0] + y * frame->linesize[0], linesize[0]);

    return 0;
}

/// Unpack 10bit value
static av_always_inline
uint16_t get10(const uint8_t *line_data, uint32_t pos, int msb_bytes)
{
    return (line_data[pos] << 2) |
        ((line_data[msb_bytes + (pos >> 2)] >> ((pos & 0x3u) << 1)) & 0x3u);
}

/// Unpack 12bit value
static av_always_inline
uint16_t get12(const uint8_t *line_data, uint32_t pos, int msb_bytes)
{
    return (line_data[pos] << 4) |
        ((line_data[msb_bytes + (pos >> 1)] >> ((pos & 0x1u) << 2)) & 0xfu);
}

static int unpack_rg10(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    const uint8_t *data = gb->buffer;
    int lw = frame->width;
    int msb_bytes = lw * 3;
    int line_offset = lw * 3 + (lw * 3 + 3) / 4;
    int pos = 0, pos_in = 0;

    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < lw; x++) {
            AV_WL16(&frame->data[2][pos], get10(data, pos_in++, msb_bytes)); // r
            AV_WL16(&frame->data[0][pos], get10(data, pos_in++, msb_bytes)); // g
            AV_WL16(&frame->data[1][pos], get10(data, pos_in++, msb_bytes)); // b
            pos += 2;
        }

        data += line_offset;
        pos_in = 0;
    }

    return 0;
}

static int unpack_y410(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    const uint8_t *data = gb->buffer;
    int lw = frame->width;
    int msb_bytes = lw * 3;
    int line_offset = lw * 3 + (lw * 3 + 3) / 4;
    int pos = 0, pos_in = 0;

    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < lw; x++) {
            AV_WL16(&frame->data[0][pos], get10(data, pos_in++, msb_bytes)); // y
            AV_WL16(&frame->data[1][pos], get10(data, pos_in++, msb_bytes)); // u
            AV_WL16(&frame->data[2][pos], get10(data, pos_in++, msb_bytes)); // v
            pos += 2;
        }
        data += line_offset;
        pos_in = 0;
    }

    return 0;
}

static int unpack_rg12(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    const uint8_t *data = gb->buffer;
    int lw = frame->width;
    int msb_bytes = lw * 3;
    int line_offset = lw * 3 + (lw * 3 + 1) / 2;
    int pos = 0, pos_in = 0;

    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < lw; x++) {
            AV_WL16(&frame->data[2][pos], get12(data, pos_in++, msb_bytes)); // r
            AV_WL16(&frame->data[0][pos], get12(data, pos_in++, msb_bytes)); // g
            AV_WL16(&frame->data[1][pos], get12(data, pos_in++, msb_bytes)); // b
            pos += 2;
        }
        data += line_offset;
        pos_in = 0;
    }
    return 0;
}

static int unpack_y412(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    const uint8_t *data = gb->buffer;
    int lw = frame->width;
    int msb_bytes = lw * 3;
    int line_offset = lw * 3 + (lw * 3 + 1) / 2;
    int pos = 0, pos_in = 0;

    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < lw; x++) {
            AV_WL16(&frame->data[0][pos], get12(data, pos_in++, msb_bytes)); // y
            AV_WL16(&frame->data[1][pos], get12(data, pos_in++, msb_bytes)); // u
            AV_WL16(&frame->data[2][pos], get12(data, pos_in++, msb_bytes)); // v
            pos += 2;
        }
        data += line_offset;
        pos_in = 0;
    }

    return 0;
}

static int unpack_y210(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    const uint8_t *data = gb->buffer;
    int lw = frame->width;
    int msb_bytes = lw * 2;
    int line_offset = lw/2 * 5;
    int pos_uv = 0, pos_y = 0, pos_in = 0;

    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < lw/2; x++) {
            AV_WL16(&frame->data[1][pos_uv],    get10(data, pos_in++, msb_bytes)); // u
            AV_WL16(&frame->data[0][pos_y],     get10(data, pos_in++, msb_bytes)); // y
            AV_WL16(&frame->data[2][pos_uv],    get10(data, pos_in++, msb_bytes)); // v
            AV_WL16(&frame->data[0][pos_y + 2], get10(data, pos_in++, msb_bytes)); // y
            pos_uv += 2;
            pos_y += 4;
        }
        data += line_offset;
        pos_in = 0;
    }

    return 0;
}

static int unpack_y212(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb)
{
    const uint8_t *data = gb->buffer;
    int lw = frame->width;
    int msb_bytes = lw * 2;
    int line_offset = lw * 3;
    int pos_uv = 0, pos_y = 0, pos_in = 0;

    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < lw/2; x++) {
            AV_WL16(&frame->data[1][pos_uv],   get12(data, pos_in++, msb_bytes)); // u
            AV_WL16(&frame->data[0][pos_y],    get12(data, pos_in++, msb_bytes)); // y
            AV_WL16(&frame->data[2][pos_uv],   get12(data, pos_in++, msb_bytes)); // v
            AV_WL16(&frame->data[0][pos_y + 2],get12(data, pos_in++, msb_bytes)); // y
            pos_uv += 2;
            pos_y += 4;
        }
        data += line_offset;
        pos_in = 0;
    }

    return 0;
}

static int check_gb_size(AVCodecContext *avctx, GetByteContext *gb, int bpp)
{
    const int needed = ((avctx->width * bpp + 7) / 8) * avctx->height;

    if (bytestream2_get_bytes_left(gb) < needed)
        return AVERROR_INVALIDDATA;

    return 0;
}

static int fmt_frame(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb,
                    enum AVPixelFormat pix_fmt, int src_bpp,
                    int (*frame_handler)(AVCodecContext *avctx, AVFrame *frame, GetByteContext *gb))
{
    int ret;

    avctx->pix_fmt = pix_fmt;

    ret = check_gb_size(avctx, gb, src_bpp);
    if (ret < 0)
        return ret;

    ret = ff_thread_get_buffer(avctx, frame, 0);
    if (ret < 0)
        return ret;

    return frame_handler(avctx, frame, gb);
}

static int dnxuc_decode_frame(AVCodecContext *avctx, AVFrame *frame,
                             int *got_frame, AVPacket *avpkt)
{
    uint32_t packet_size, box_header, fourcc, buffer_size;
    GetByteContext gbc;
    GetByteContext *gb = &gbc;
    char fourcc_buf[AV_FOURCC_MAX_STRING_SIZE];
    int ret, w, h, interlaced;

    bytestream2_init(gb, avpkt->data, avpkt->size);

    packet_size = bytestream2_get_le32(gb);
    if (packet_size > avpkt->size)
        return AVERROR_INVALIDDATA;

    box_header = bytestream2_get_le32(gb);
    if (box_header != MKTAG('p','a','c','k'))
        return AVERROR_INVALIDDATA;
    bytestream2_skip(gb, 4);

    box_header = bytestream2_get_le32(gb);
    if (box_header != MKTAG('s','i','n','f'))
        return AVERROR_INVALIDDATA;

    w = bytestream2_get_le32(gb);
    h = bytestream2_get_le32(gb);
    if ((ret = ff_set_dimensions(avctx, w, h)) < 0)
        return ret;

    fourcc = bytestream2_get_le32(gb);
    interlaced = bytestream2_get_byte(gb) == 1;

    buffer_size = bytestream2_get_le32(gb);
    if (buffer_size - 4 > bytestream2_get_bytes_left(gb))
        return AVERROR_INVALIDDATA;

    box_header = bytestream2_get_le32(gb);
    if (box_header != MKTAG('s','d','a','t'))
        return AVERROR_INVALIDDATA;

    av_fourcc_make_string(fourcc_buf, fourcc);
    if ((avctx->width % 2) && ((fourcc_buf[0] == 'y' && fourcc_buf[1] == '2')
                             ||(fourcc_buf[1] == 'y' && fourcc_buf[2] == '2'))) {
        av_log(avctx, AV_LOG_ERROR,
        "Image width must be a multiple of 2 for YUV 4:2:2 DNxUncompressed!\n");
        return AVERROR_INVALIDDATA;
    }

    switch (fourcc) {
    case MKTAG('y','2','0','8'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_UYVY422, 16, pass_through);
        break;
    case MKTAG('y','2','1','0'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_YUV422P10LE, 20, unpack_y210);
        break;
    case MKTAG('y','4','1','0'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_YUV444P10LE, 20, unpack_y410);
        break;
    case MKTAG('y','2','1','2'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_YUV422P12LE, 24, unpack_y212);
        break;
    case MKTAG('y','4','1','2'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_YUV444P12LE, 24, unpack_y412);
        break;

    case MKTAG('r','g','0','8'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_RGB24, 24, pass_through);
        break;
    case MKTAG('r','g','1','0'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_GBRP10LE, 30, unpack_rg10);
        break;
    case MKTAG('r','g','1','2'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_GBRP12LE, 36, unpack_rg12);
        break;
    case MKTAG('r','g','1','6'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_RGB48LE, 48, pass_through);
        break;
    case MKTAG(' ','r','g','h'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_RGBF16LE, 48, pass_through);
        break;
    case MKTAG(' ','r','g','f'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_RGBF32LE, 96, pass_through);
        break;

    case MKTAG(' ','a','0','8'):
    case MKTAG(' ','y','0','8'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_GRAY8, 8, pass_through);
        break;
    case MKTAG(' ','a','1','6'):
    case MKTAG(' ','y','1','6'):
        ret = fmt_frame(avctx, frame, gb, AV_PIX_FMT_GRAY16LE, 16, pass_through);
        break;

    default:
        avpriv_request_sample(avctx,
                              "Unsupported DNxUncompressed pixel format variant: '%s'",
                              fourcc_buf);
        return AVERROR_PATCHWELCOME;
    }

    if (ret < 0)
        return ret;

    frame->flags |= AV_FRAME_FLAG_INTERLACED * interlaced;

    *got_frame = 1;

    return avpkt->size;
}

const FFCodec ff_dnxuc_decoder = {
    .p.name         = "dnxuc",
    CODEC_LONG_NAME("DNxUncompressed (SMPTE RDD 50)"),
    .p.type         = AVMEDIA_TYPE_VIDEO,
    .p.id           = AV_CODEC_ID_DNXUC,
    FF_CODEC_DECODE_CB(dnxuc_decode_frame),
    .p.capabilities = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_FRAME_THREADS,
};
